{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -1.47212654e-01   1.01060428e-01   5.75077347e-02  -6.01155460e-02\n",
      "  -8.52212533e-02  -2.85948534e-02  -1.54139921e-02  -9.34570208e-02\n",
      "   9.29960981e-02  -6.14694096e-02   2.88503498e-01  -9.82552245e-02\n",
      "  -2.71969587e-01  -1.32094026e-01  -1.47302877e-02   2.00097218e-01\n",
      "  -2.20905215e-01  -1.23891562e-01   2.28404105e-02  -2.04225164e-02\n",
      "   1.44576296e-01  -2.72824820e-02  -4.68037650e-03   6.11106418e-02\n",
      "  -1.76215455e-01  -3.07795405e-01  -5.75121865e-02  -8.87441412e-02\n",
      "   3.32456604e-02  -7.76547566e-02  -4.81905527e-02  -2.73876842e-02\n",
      "  -2.32954472e-01  -7.92512149e-02  -5.02711882e-05   6.23329356e-02\n",
      "   8.44052061e-03  -5.81598431e-02   1.66577488e-01  -2.12363843e-02\n",
      "  -2.29406059e-01   2.03036126e-02   5.06373011e-02   2.30019689e-01\n",
      "   1.06520616e-01   1.05253361e-01   4.25674096e-02  -1.19306751e-01\n",
      "   9.45178941e-02  -1.98096171e-01   3.47764865e-02   1.37570933e-01\n",
      "   7.86105916e-02  -1.00779850e-02  -5.05996421e-02  -1.48426071e-01\n",
      "  -1.37734031e-02   1.55238390e-01  -2.13298336e-01   4.57745828e-02\n",
      "   8.32562819e-02  -5.26688434e-02   1.25208506e-02  -8.33173618e-02\n",
      "   2.08452001e-01   3.26862037e-02  -1.58177659e-01  -1.26308635e-01\n",
      "   8.07076767e-02  -1.10771924e-01  -6.95158690e-02   7.70173818e-02\n",
      "  -1.29851997e-01  -2.07100719e-01  -3.80931109e-01   5.46643399e-02\n",
      "   4.06038195e-01   7.55726174e-02  -1.40321389e-01   2.23947037e-02\n",
      "  -3.97678725e-02   4.51239466e-04   1.24664754e-01   1.64112344e-01\n",
      "  -6.85089780e-03   2.57432852e-02  -1.07224122e-01   4.62245941e-02\n",
      "   1.82833642e-01  -7.62235075e-02  -5.51092951e-03   2.00946882e-01\n",
      "  -1.48808695e-02   7.29322284e-02  -5.18962741e-02   9.90491956e-02\n",
      "  -1.14765801e-01   4.51615490e-02  -2.99762357e-02   2.15829886e-03\n",
      "   5.18242009e-02   2.75163236e-03   3.16213369e-02   1.49143234e-01\n",
      "  -1.62603378e-01   7.56467208e-02  -2.55276095e-02  -1.34788556e-02\n",
      "  -2.42296066e-02  -1.06125902e-02  -5.26066683e-02  -8.00777376e-02\n",
      "   5.13774753e-02  -2.47448429e-01   1.65274009e-01   2.46132448e-01\n",
      "   1.01814093e-02   9.74354073e-02   1.09524027e-01   2.68477835e-02\n",
      "   1.36430319e-02  -1.41043903e-03  -2.15486810e-01  -3.82524207e-02\n",
      "   1.17121257e-01  -5.68333678e-02   1.48321882e-01  -2.75853742e-02]\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# looking for dir in jupyrt is different with normal .py file, we use pathlib and Path().resolve()\n",
    "BASE_DIR = Path().resolve()\n",
    "# images directory\n",
    "image_dir = os.path.join(BASE_DIR, \"images/khai/1.jpg\")\n",
    "# Load the jpg files into numpy arrays\n",
    "image = face_recognition.load_image_file(image_dir)\n",
    "\n",
    "# Generate the face encodings\n",
    "face_encodings = face_recognition.face_encodings(image)\n",
    "\n",
    "if len(face_encodings) == 0:\n",
    "    # No faces found in the image.\n",
    "    print(\"No faces were found.\")\n",
    "\n",
    "else:\n",
    "    # Grab the first face encoding\n",
    "    first_face_encoding = face_encodings[0]\n",
    "\n",
    "    # Print the results\n",
    "    print(first_face_encoding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found 1 face(s) in this photograph.\n",
      "A face is located at pixel location Top: 418, Left: 161, Bottom: 804, Right: 546\n"
     ]
    }
   ],
   "source": [
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "import face_recognition\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# looking for dir in jupyrt is different with normal .py file, we use pathlib and Path().resolve()\n",
    "BASE_DIR = Path().resolve()\n",
    "# images directory\n",
    "image_dir = os.path.join(BASE_DIR, \"images/khai/1.jpg\")\n",
    "# Load the jpg files into numpy arrays\n",
    "image = face_recognition.load_image_file(image_dir)\n",
    "# Find all the faces in the image\n",
    "face_locations = face_recognition.face_locations(image)\n",
    "\n",
    "number_of_faces = len(face_locations)\n",
    "print(\"I found {} face(s) in this photograph.\".format(number_of_faces))\n",
    "\n",
    "# Load the image into a Python Image Library object so that we can draw on top of it and display it\n",
    "pil_image = PIL.Image.fromarray(image)\n",
    "\n",
    "for face_location in face_locations:\n",
    "\n",
    "    # Print the location of each face in this image. Each face is a list of co-ordinates in (top, right, bottom, left) order.\n",
    "    top, right, bottom, left = face_location\n",
    "    print(\"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right))\n",
    "\n",
    "    # Let's draw a box around the face\n",
    "    draw = PIL.ImageDraw.Draw(pil_image)\n",
    "    draw.rectangle([left, top, right, bottom], outline=\"red\")\n",
    "\n",
    "# Display the image on screen\n",
    "pil_image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
